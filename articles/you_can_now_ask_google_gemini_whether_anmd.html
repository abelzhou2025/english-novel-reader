<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>You Can Now Ask Google Gemini Whether an Image is AI-Generated or Not - English Novel Reader</title>
    <link rel="stylesheet" href="../styles.css">
    <style>
        /* Article reader specific styles */
        .article-content {
            max-width: 800px;
            margin: 100px auto;
            padding: 30px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        
        .article-title {
            font-size: 1.8rem;
            color: #5a3e2b;
            margin-bottom: 10px;
            font-family: Georgia, serif;
        }
        
        .article-title-chinese {
            font-size: 1.2rem;
            color: #666;
            margin-bottom: 30px;
            font-family: 'Microsoft YaHei', sans-serif;
            opacity: 0.8;
        }
        
        .article-paragraph {
            margin-bottom: 25px;
            line-height: 1.8;
        }
        
        .english-text {
            font-family: Georgia, serif;
            font-size: 1.1rem;
            color: #333;
            margin-bottom: 15px;
        }
        
        .chinese-text {
            font-family: 'Microsoft YaHei', sans-serif;
            font-size: 1rem;
            color: #666;
            opacity: 0.7;
            margin-bottom: 30px;
            padding-left: 20px;
            border-left: 3px solid #d4a76a;
        }
        
        .back-btn {
            display: inline-block;
            background-color: #5a3e2b;
            color: #fff;
            padding: 10px 20px;
            border-radius: 6px;
            text-decoration: none;
            font-family: 'Microsoft YaHei', sans-serif;
            font-size: 1rem;
            transition: all 0.3s ease;
            margin-bottom: 30px;
        }
        
        .back-btn:hover {
            background-color: #7a5c42;
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        
        .loading-translation {
            font-style: italic;
            color: #999;
        }
    </style>
</head>
<body>
    <!-- Top Navigation -->
    <nav class="top-nav">
        <ul>
            <li><a href="../index.html">小说</a></li>
            <li><a href="../webnovels.html">网文</a></li>
            <li><a href="../about.html">关于我</a></li>
        </ul>
    </nav>
    
    <div class="container">
        <div class="main-content">
            <div class="article-content">
                <a href="../webnovels.html" class="back-btn">← 返回网文列表</a>
                <h1 class="article-title">You Can Now Ask Google Gemini Whether an Image is AI-Generated or Not</h1>
                <div class="article-title-chinese loading-translation" data-english="You Can Now Ask Google Gemini Whether an Image is AI-Generated or Not">正在翻译标题...</div>
                <div id="articleBody">
                    <div class="article-paragraph">
                        <div class="english-text">Google has a new feature that allows users to find out whether an image is AI-generated or not --- a much-needed tool in a world of AI slop.</div>
                        <div class="chinese-text loading-translation" data-english="Google has a new feature that allows users to find out whether an image is AI-generated or not --- a much-needed tool in a world of AI slop.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">The new feature is available via Google Gemini 3, the latest installment of the company's LLM and multi-modal AI. To ascertain whether an image is AI-generated, simply open the Gemini app, upload the image, and ask something like: "Is this image AI-generated?"</div>
                        <div class="chinese-text loading-translation" data-english="The new feature is available via Google Gemini 3, the latest installment of the company's LLM and multi-modal AI. To ascertain whether an image is AI-generated, simply open the Gemini app, upload the image, and ask something like: "Is this image AI-generated?"">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">Gemini will give an answer, but it is predicated on whether that image contains SynthID, Google's digital watermarking technology that "embeds imperceptible signals into AI-generated content." Images that have been generated on one of Google's models, like Nano Banana, for example, will be flagged by Gemini as AI.</div>
                        <div class="chinese-text loading-translation" data-english="Gemini will give an answer, but it is predicated on whether that image contains SynthID, Google's digital watermarking technology that "embeds imperceptible signals into AI-generated content." Images that have been generated on one of Google's models, like Nano Banana, for example, will be flagged by Gemini as AI.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">1/100:21PetaPixel RSS  watchingPolarPro's Knife for Photographers Does More Than Cut Stuffafter the ad</div>
                        <div class="chinese-text loading-translation" data-english="1/100:21PetaPixel RSS  watchingPolarPro's Knife for Photographers Does More Than Cut Stuffafter the ad">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"We introduced SynthID in 2023," Google says in a blog post. "Since then, over 20 billion AI-generated pieces of content have been watermarked using SynthID, and we have been testing our SynthID Detector, a verification portal, with journalists and media professionals."</div>
                        <div class="chinese-text loading-translation" data-english=""We introduced SynthID in 2023," Google says in a blog post. "Since then, over 20 billion AI-generated pieces of content have been watermarked using SynthID, and we have been testing our SynthID Detector, a verification portal, with journalists and media professionals."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">While SynthID is Google's technology, the company says that it will "continue to invest in more ways to empower you to determine the origin and history of content online." It plans to incorporate the Coalition for Content Provenance and Authority (C2PA) standard so users will be able to check the provenance of an image created by AI models outside of Google's ecosystem.</div>
                        <div class="chinese-text loading-translation" data-english="While SynthID is Google's technology, the company says that it will "continue to invest in more ways to empower you to determine the origin and history of content online." It plans to incorporate the Coalition for Content Provenance and Authority (C2PA) standard so users will be able to check the provenance of an image created by AI models outside of Google's ecosystem.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"As part of this, rolling out this week, images generated by Nano Banana Pro (Gemini 3 Pro Image) in the Gemini app, Vertex AI, and Google Ads will have C2PA metadata embedded, providing further transparency into how these images were created," Google adds. "We look forward to expanding this capability to more products and surfaces in the coming months."</div>
                        <div class="chinese-text loading-translation" data-english=""As part of this, rolling out this week, images generated by Nano Banana Pro (Gemini 3 Pro Image) in the Gemini app, Vertex AI, and Google Ads will have C2PA metadata embedded, providing further transparency into how these images were created," Google adds. "We look forward to expanding this capability to more products and surfaces in the coming months."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">I put Gemini's latest model to the test to see whether it can accurately spot an AI-generated image. Results below.
 First, I uploaded a real photo to Gemini. It correctly declared the image "was not created with Google AI."  Then, I uploaded an AI image made by ChatGPT. OpenAI does not use the SynthID system, which Gemini recognized. However, it did pick up on "several tell-tale signs" typical of AI-generated imagery. It highlighted the distorted Starbucks logos on the cups and the "blocky" look of the cartoon. It even went on to specifically name ChatGPT as the potential source.  Finally, I uploaded a photo edited on Google's AI studio. It picked up the SynthID and declared it to be "all or part" created with Google AI. It also comically picked up on "unrealistic animal behavior."</div>
                        <div class="chinese-text loading-translation" data-english="I put Gemini's latest model to the test to see whether it can accurately spot an AI-generated image. Results below.
 First, I uploaded a real photo to Gemini. It correctly declared the image "was not created with Google AI."  Then, I uploaded an AI image made by ChatGPT. OpenAI does not use the SynthID system, which Gemini recognized. However, it did pick up on "several tell-tale signs" typical of AI-generated imagery. It highlighted the distorted Starbucks logos on the cups and the "blocky" look of the cartoon. It even went on to specifically name ChatGPT as the potential source.  Finally, I uploaded a photo edited on Google's AI studio. It picked up the SynthID and declared it to be "all or part" created with Google AI. It also comically picked up on "unrealistic animal behavior."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">So far, so good---and once C2PA is added, the system will feel much more complete. The best part is that it offers a relatively simple way to check whether an image was generated by AI. Photographers should consider adding a C2PA signature to their own photos, which can be done easily in Lightroom or Photoshop.</div>
                        <div class="chinese-text loading-translation" data-english="So far, so good---and once C2PA is added, the system will feel much more complete. The best part is that it offers a relatively simple way to check whether an image was generated by AI. Photographers should consider adding a C2PA signature to their own photos, which can be done easily in Lightroom or Photoshop.">正在翻译...</div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <script src="../script.js"></script>
    <script>
        // Translation cache management
        const TRANSLATION_CACHE = {
            get: (key) => {
                try {
                    const cacheItem = localStorage.getItem('translation_' + key);
                    if (cacheItem) {
                        const parsed = JSON.parse(cacheItem);
                        // Check if cache is still valid (7 days)
                        if (Date.now() - parsed.timestamp < 7 * 24 * 60 * 60 * 1000) {
                            return parsed.translation;
                        }
                    }
                } catch (e) {
                    console.error('Cache read error:', e);
                }
                return null;
            },
            set: (key, translation) => {
                try {
                    localStorage.setItem('translation_' + key, JSON.stringify({
                        translation,
                        timestamp: Date.now()
                    }));
                } catch (e) {
                    console.error('Cache write error:', e);
                }
            }
        };
        
        // Function to translate a paragraph with caching
        async function translateParagraph(text, element) {
            // Generate cache key from text
            const cacheKey = btoa(text.trim().toLowerCase());
            
            // Check if translation is in cache
            const cachedTranslation = TRANSLATION_CACHE.get(cacheKey);
            if (cachedTranslation) {
                element.textContent = cachedTranslation;
                element.classList.remove('loading-translation');
                return;
            }
            
            // Translation APIs configuration
            const apis = [
                {
                    name: 'MyMemory',
                    url: 'https://api.mymemory.translated.net/get?q=' + encodeURIComponent(text) + '&langpair=en|zh'
                },
                {
                    name: 'Google Translate',
                    url: 'https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=zh-CN&dt=t&q=' + encodeURIComponent(text)
                }
            ];
            
            // Try APIs in order
            for (const api of apis) {
                try {
                    const response = await fetch(api.url, {
                        mode: 'cors',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        // Add timeout for faster failure on slow connections
                        signal: AbortSignal.timeout(5000)
                    });
                    
                    if (api.name === 'MyMemory') {
                        const data = await response.json();
                        if (data.responseStatus === 200 && data.responseData.translatedText) {
                            const translation = data.responseData.translatedText;
                            TRANSLATION_CACHE.set(cacheKey, translation);
                            element.textContent = translation;
                            element.classList.remove('loading-translation');
                            return;
                        }
                    } else if (api.name === 'Google Translate') {
                        const data = await response.json();
                        if (data && data[0] && Array.isArray(data[0])) {
                            const translation = data[0].map(function(item) { return item[0]; }).join('');
                            if (translation) {
                                TRANSLATION_CACHE.set(cacheKey, translation);
                                element.textContent = translation;
                                element.classList.remove('loading-translation');
                                return;
                            }
                        }
                    }
                } catch (error) {
                    console.error(api.name + ' translation error:', error);
                    // Continue to next API if current one fails
                    continue;
                }
            }
            
            // Fallback if all APIs fail
            const fallbackTranslation = element.classList.contains('article-title-chinese') ? '文章标题翻译' : '这是文章内容的中文翻译。';
            element.textContent = fallbackTranslation;
            element.classList.remove('loading-translation');
        }
        
        // Translate all paragraphs when the page loads with optimized concurrency
        document.addEventListener('DOMContentLoaded', function() {
            const chineseTexts = document.querySelectorAll('.chinese-text, .article-title-chinese');
            
            // Limit concurrent translations to avoid overloading API
            const CONCURRENCY_LIMIT = 3;
            let activeTranslations = 0;
            let index = 0;
            
            // Function to process next translation
            const processNext = function() {
                if (index >= chineseTexts.length) return;
                
                // Wait if we've reached concurrency limit
                if (activeTranslations >= CONCURRENCY_LIMIT) {
                    setTimeout(processNext, 100);
                    return;
                }
                
                const element = chineseTexts[index++];
                const englishText = element.getAttribute('data-english');
                
                activeTranslations++;
                translateParagraph(englishText, element)
                    .finally(function() {
                        activeTranslations--;
                        processNext(); // Process next translation when current one finishes
                    });
            };
            
            // Start processing translations
            for (let i = 0; i < CONCURRENCY_LIMIT; i++) {
                processNext();
            }
        });
    </script>
</body>
</html>