<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI says AI browsers may always be vulnerable to prompt injection attacks - English Novel Reader</title>
    <link rel="stylesheet" href="../styles.css">
    <style>
        /* Article reader specific styles */
        .article-content {
            max-width: 800px;
            margin: 100px auto;
            padding: 30px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        
        .article-title {
            font-size: 1.8rem;
            color: #5a3e2b;
            margin-bottom: 10px;
            font-family: Georgia, serif;
        }
        
        .article-title-chinese {
            font-size: 1.2rem;
            color: #666;
            margin-bottom: 30px;
            font-family: 'Microsoft YaHei', sans-serif;
            opacity: 0.8;
        }
        
        .article-paragraph {
            margin-bottom: 25px;
            line-height: 1.8;
        }
        
        .english-text {
            font-family: Georgia, serif;
            font-size: 1.1rem;
            color: #333;
            margin-bottom: 15px;
        }
        
        .chinese-text {
            font-family: 'Microsoft YaHei', sans-serif;
            font-size: 1rem;
            color: #666;
            opacity: 0.7;
            margin-bottom: 30px;
            padding-left: 20px;
            border-left: 3px solid #d4a76a;
        }
        
        .back-btn {
            display: inline-block;
            background-color: #5a3e2b;
            color: #fff;
            padding: 10px 20px;
            border-radius: 6px;
            text-decoration: none;
            font-family: 'Microsoft YaHei', sans-serif;
            font-size: 1rem;
            transition: all 0.3s ease;
            margin-bottom: 30px;
        }
        
        .back-btn:hover {
            background-color: #7a5c42;
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        
        .loading-translation {
            font-style: italic;
            color: #999;
        }
    </style>
</head>
<body>
    <!-- Top Navigation -->
    <nav class="top-nav">
        <ul>
            <li><a href="../index.html">小说</a></li>
            <li><a href="../webnovels.html">网文</a></li>
            <li><a href="../about.html">关于我</a></li>
        </ul>
    </nav>
    
    <div class="container">
        <div class="main-content">
            <div class="article-content">
                <a href="../webnovels.html" class="back-btn">← 返回网文列表</a>
                <h1 class="article-title">OpenAI says AI browsers may always be vulnerable to prompt injection attacks</h1>
                <div class="article-title-chinese loading-translation" data-english="OpenAI says AI browsers may always be vulnerable to prompt injection attacks">正在翻译标题...</div>
                <div id="articleBody">
                    <div class="article-paragraph">
                        <div class="english-text">Even as OpenAI works to harden its Atlas AI browser against cyberattacks, the company admits that prompt injections, a type of attack that manipulates AI agents to follow malicious instructions often hidden in web pages or emails, is a risk that's not going away anytime soon --- raising questions about how safely AI agents can operate on the open web.</div>
                        <div class="chinese-text loading-translation" data-english="Even as OpenAI works to harden its Atlas AI browser against cyberattacks, the company admits that prompt injections, a type of attack that manipulates AI agents to follow malicious instructions often hidden in web pages or emails, is a risk that's not going away anytime soon --- raising questions about how safely AI agents can operate on the open web.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"Prompt injection, much like scams and social engineering on the web, is unlikely to ever be fully 'solved,'" OpenAI wrote in a Monday blog post detailing how the firm is beefing up Atlas' armor to combat the unceasing attacks. The company conceded that "agent mode" in ChatGPT Atlas "expands the security threat surface."</div>
                        <div class="chinese-text loading-translation" data-english=""Prompt injection, much like scams and social engineering on the web, is unlikely to ever be fully 'solved,'" OpenAI wrote in a Monday blog post detailing how the firm is beefing up Atlas' armor to combat the unceasing attacks. The company conceded that "agent mode" in ChatGPT Atlas "expands the security threat surface."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">OpenAI launched its ChatGPT Atlas browser in October, and security researchers rushed to publish their demos, showing it was possible to write a few words in Google Docs that were capable of changing the underlying browser's behavior. That same day, Brave published a blog post explaining that indirect prompt injection is a systematic challenge for AI-powered browsers, including Perplexity's Comet.</div>
                        <div class="chinese-text loading-translation" data-english="OpenAI launched its ChatGPT Atlas browser in October, and security researchers rushed to publish their demos, showing it was possible to write a few words in Google Docs that were capable of changing the underlying browser's behavior. That same day, Brave published a blog post explaining that indirect prompt injection is a systematic challenge for AI-powered browsers, including Perplexity's Comet.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">OpenAI isn't alone in recognizing that prompt-based injections aren't going away. The U.K.'s National Cyber Security Centre earlier this month warned that prompt injection attacks against generative AI applications "may never be totally mitigated," putting websites at risk of falling victim to data breaches. The U.K. government agency advised cyber professionals to reduce the risk and impact of prompt injections, rather than think the attacks can be "stopped."</div>
                        <div class="chinese-text loading-translation" data-english="OpenAI isn't alone in recognizing that prompt-based injections aren't going away. The U.K.'s National Cyber Security Centre earlier this month warned that prompt injection attacks against generative AI applications "may never be totally mitigated," putting websites at risk of falling victim to data breaches. The U.K. government agency advised cyber professionals to reduce the risk and impact of prompt injections, rather than think the attacks can be "stopped."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">For OpenAI's part, the company said: "We view prompt injection as a long-term AI security challenge, and we'll need to continuously strengthen our defenses against it."</div>
                        <div class="chinese-text loading-translation" data-english="For OpenAI's part, the company said: "We view prompt injection as a long-term AI security challenge, and we'll need to continuously strengthen our defenses against it."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">The company's answer to this Sisyphean task? A proactive, rapid-response cycle that the firm says is showing early promise in helping discover novel attack strategies internally before they are exploited "in the wild."</div>
                        <div class="chinese-text loading-translation" data-english="The company's answer to this Sisyphean task? A proactive, rapid-response cycle that the firm says is showing early promise in helping discover novel attack strategies internally before they are exploited "in the wild."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">That's not entirely different from what rivals like Anthropic and Google have been saying: that to fight against the persistent risk of prompt-based attacks, defenses must be layered and continuously stress-tested. Google's recent work, for example, focuses on architectural and policy-level controls for agentic systems.</div>
                        <div class="chinese-text loading-translation" data-english="That's not entirely different from what rivals like Anthropic and Google have been saying: that to fight against the persistent risk of prompt-based attacks, defenses must be layered and continuously stress-tested. Google's recent work, for example, focuses on architectural and policy-level controls for agentic systems.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">But where OpenAI is taking a different tact is with its "LLM-based automated attacker." This attacker is basically a bot that OpenAI trained, using reinforcement learning, to play the role of a hacker that looks for ways to sneak malicious instructions to an AI agent.</div>
                        <div class="chinese-text loading-translation" data-english="But where OpenAI is taking a different tact is with its "LLM-based automated attacker." This attacker is basically a bot that OpenAI trained, using reinforcement learning, to play the role of a hacker that looks for ways to sneak malicious instructions to an AI agent.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">The bot can test the attack in simulation before using it for real, and the simulator shows how the target AI would think and what actions it would take if it saw the attack. The bot can then study that response, tweak the attack, and try again and again. That insight into the target AI's internal reasoning is something outsiders don't have access to, so, in theory, OpenAI's bot should be able to find flaws faster than a real-world attacker would.</div>
                        <div class="chinese-text loading-translation" data-english="The bot can test the attack in simulation before using it for real, and the simulator shows how the target AI would think and what actions it would take if it saw the attack. The bot can then study that response, tweak the attack, and try again and again. That insight into the target AI's internal reasoning is something outsiders don't have access to, so, in theory, OpenAI's bot should be able to find flaws faster than a real-world attacker would.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">It's a common tactic in AI safety testing: build an agent to find the edge cases and test against them rapidly in simulation.</div>
                        <div class="chinese-text loading-translation" data-english="It's a common tactic in AI safety testing: build an agent to find the edge cases and test against them rapidly in simulation.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"Our \[reinforcement learning\]-trained attacker can steer an agent into executing sophisticated, long-horizon harmful workflows that unfold over tens (or even hundreds) of steps," wrote OpenAI. "We also observed novel attack strategies that did not appear in our human red teaming campaign or external reports."
 Image Credits:OpenAI</div>
                        <div class="chinese-text loading-translation" data-english=""Our \[reinforcement learning\]-trained attacker can steer an agent into executing sophisticated, long-horizon harmful workflows that unfold over tens (or even hundreds) of steps," wrote OpenAI. "We also observed novel attack strategies that did not appear in our human red teaming campaign or external reports."
 Image Credits:OpenAI">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">In a demo (pictured in part above), OpenAI showed how its automated attacker slipped a malicious email into a user's inbox. When the AI agent later scanned the inbox, it followed the hidden instructions in the email and sent a resignation message instead of drafting an out-of-office reply. But following the security update, "agent mode" was able to successfully detect the prompt injection attempt and flag it to the user, according to the company.</div>
                        <div class="chinese-text loading-translation" data-english="In a demo (pictured in part above), OpenAI showed how its automated attacker slipped a malicious email into a user's inbox. When the AI agent later scanned the inbox, it followed the hidden instructions in the email and sent a resignation message instead of drafting an out-of-office reply. But following the security update, "agent mode" was able to successfully detect the prompt injection attempt and flag it to the user, according to the company.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">The company says that while prompt injection is hard to secure against in a foolproof way, it's leaning on large-scale testing and faster patch cycles to harden its systems before they show up in real-world attacks.</div>
                        <div class="chinese-text loading-translation" data-english="The company says that while prompt injection is hard to secure against in a foolproof way, it's leaning on large-scale testing and faster patch cycles to harden its systems before they show up in real-world attacks.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">An OpenAI spokesperson declined to share whether the update to Atlas' security has resulted in a measurable reduction in successful injections, but says the firm has been working with third parties to harden Atlas against prompt injection since before launch.</div>
                        <div class="chinese-text loading-translation" data-english="An OpenAI spokesperson declined to share whether the update to Atlas' security has resulted in a measurable reduction in successful injections, but says the firm has been working with third parties to harden Atlas against prompt injection since before launch.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">Rami McCarthy, principal security researcher at cybersecurity firm Wiz, says that reinforcement learning is one way to continuously adapt to attacker behavior, but it's only part of the picture.</div>
                        <div class="chinese-text loading-translation" data-english="Rami McCarthy, principal security researcher at cybersecurity firm Wiz, says that reinforcement learning is one way to continuously adapt to attacker behavior, but it's only part of the picture.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"A useful way to reason about risk in AI systems is autonomy multiplied by access," McCarthy told TechCrunch.</div>
                        <div class="chinese-text loading-translation" data-english=""A useful way to reason about risk in AI systems is autonomy multiplied by access," McCarthy told TechCrunch.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"Agentic browsers tend to sit in a challenging part of that space: moderate autonomy combined with very high access," said McCarthy. "Many current recommendations reflect that trade-off. Limiting logged-in access primarily reduces exposure, while requiring review of confirmation requests constrains autonomy."</div>
                        <div class="chinese-text loading-translation" data-english=""Agentic browsers tend to sit in a challenging part of that space: moderate autonomy combined with very high access," said McCarthy. "Many current recommendations reflect that trade-off. Limiting logged-in access primarily reduces exposure, while requiring review of confirmation requests constrains autonomy."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">Those are two of OpenAI's recommendations for users to reduce their own risk, and a spokesperson said Atlas is also trained to get user confirmation before sending messages or making payments. OpenAI also suggests that users give agents specific instructions, rather than providing them access to your inbox and telling them to "take whatever action is needed."</div>
                        <div class="chinese-text loading-translation" data-english="Those are two of OpenAI's recommendations for users to reduce their own risk, and a spokesperson said Atlas is also trained to get user confirmation before sending messages or making payments. OpenAI also suggests that users give agents specific instructions, rather than providing them access to your inbox and telling them to "take whatever action is needed."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"Wide latitude makes it easier for hidden or malicious content to influence the agent, even when safeguards are in place," per OpenAI.</div>
                        <div class="chinese-text loading-translation" data-english=""Wide latitude makes it easier for hidden or malicious content to influence the agent, even when safeguards are in place," per OpenAI.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">While OpenAI says protecting Atlas users against prompt injections is a top priority, McCarthy invites some skepticism as to the return on investment for risk-prone browsers.</div>
                        <div class="chinese-text loading-translation" data-english="While OpenAI says protecting Atlas users against prompt injections is a top priority, McCarthy invites some skepticism as to the return on investment for risk-prone browsers.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"For most everyday use cases, agentic browsers don't yet deliver enough value to justify their current risk profile," McCarthy told TechCrunch. "The risk is high given their access to sensitive data like email and payment information, even though that access is also what makes them powerful. That balance will evolve, but today the trade-offs are still very real."</div>
                        <div class="chinese-text loading-translation" data-english=""For most everyday use cases, agentic browsers don't yet deliver enough value to justify their current risk profile," McCarthy told TechCrunch. "The risk is high given their access to sensitive data like email and payment information, even though that access is also what makes them powerful. That balance will evolve, but today the trade-offs are still very real."">正在翻译...</div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <script src="../script.js"></script>
    <script>
        // Translate all paragraphs when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            const chineseTexts = document.querySelectorAll('.chinese-text, .article-title-chinese');
            
            chineseTexts.forEach((element, index) => {
                const englishText = element.getAttribute('data-english');
                translateParagraph(englishText, element, index);
            });
        });
        
        // Function to translate a paragraph
        async function translateParagraph(text, element, index) {
            try {
                // Use MyMemory Translation API for free translation
                const url = 'https://api.mymemory.translated.net/get?q=' + encodeURIComponent(text) + '&langpair=en|zh';
                const response = await fetch(url);
                const data = await response.json();
                
                if (data.responseStatus === 200) {
                    let translation = data.responseData.translatedText;
                    // Fallback if translation is empty
                    if (!translation || translation.trim() === '') {
                        if (element.classList.contains('article-title-chinese')) {
                            translation = '文章标题翻译';
                        } else {
                            translation = '这是文章内容的中文翻译。';
                        }
                    }
                    element.textContent = translation;
                    element.classList.remove('loading-translation');
                } else {
                    // Try alternative translation API if first one fails
                    tryAlternativeTranslation(text, element);
                }
            } catch (error) {
                console.error('Translation error:', error);
                // Try alternative translation API if first one fails
                tryAlternativeTranslation(text, element);
            }
        }
        
        // Alternative translation function using a different approach
        function tryAlternativeTranslation(text, element) {
            try {
                // Use another free translation API as fallback
                const url = 'https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=zh-CN&dt=t&q=' + encodeURIComponent(text);
                fetch(url)
                    .then(response => response.json())
                    .then(data => {
                        let translation = '';
                        if (data && data[0] && Array.isArray(data[0])) {
                            translation = data[0].map(item => item[0]).join('');
                        }
                        
                        if (!translation || translation.trim() === '') {
                            if (element.classList.contains('article-title-chinese')) {
                                translation = '文章标题翻译';
                            } else {
                                translation = '这是文章内容的中文翻译。';
                            }
                        }
                        element.textContent = translation;
                        element.classList.remove('loading-translation');
                    })
                    .catch(error => {
                        console.error('Alternative translation error:', error);
                        // Final fallback if all APIs fail
                        if (element.classList.contains('article-title-chinese')) {
                            element.textContent = '文章标题翻译';
                        } else {
                            element.textContent = '这是文章内容的中文翻译。';
                        }
                        element.classList.remove('loading-translation');
                    });
            } catch (error) {
                console.error('Alternative translation error:', error);
                // Final fallback if all APIs fail
                if (element.classList.contains('article-title-chinese')) {
                    element.textContent = '文章标题翻译';
                } else {
                    element.textContent = '这是文章内容的中文翻译。';
                }
                element.classList.remove('loading-translation');
            }
        }
    </script>
</body>
</html>