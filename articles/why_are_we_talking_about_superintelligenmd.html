<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Why Are We Talking About Superintelligence? - English Novel Reader</title>
    <link rel="stylesheet" href="../styles.css">
    <style>
        /* Article reader specific styles */
        .article-content {
            max-width: 800px;
            margin: 100px auto;
            padding: 30px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        
        .article-title {
            font-size: 1.8rem;
            color: #5a3e2b;
            margin-bottom: 10px;
            font-family: Georgia, serif;
        }
        
        .article-title-chinese {
            font-size: 1.2rem;
            color: #666;
            margin-bottom: 30px;
            font-family: 'Microsoft YaHei', sans-serif;
            opacity: 0.8;
        }
        
        .article-paragraph {
            margin-bottom: 25px;
            line-height: 1.8;
        }
        
        .english-text {
            font-family: Georgia, serif;
            font-size: 1.1rem;
            color: #333;
            margin-bottom: 15px;
        }
        
        .chinese-text {
            font-family: 'Microsoft YaHei', sans-serif;
            font-size: 1rem;
            color: #666;
            opacity: 0.7;
            margin-bottom: 30px;
            padding-left: 20px;
            border-left: 3px solid #d4a76a;
        }
        
        .back-btn {
            display: inline-block;
            background-color: #5a3e2b;
            color: #fff;
            padding: 10px 20px;
            border-radius: 6px;
            text-decoration: none;
            font-family: 'Microsoft YaHei', sans-serif;
            font-size: 1rem;
            transition: all 0.3s ease;
            margin-bottom: 30px;
        }
        
        .back-btn:hover {
            background-color: #7a5c42;
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        
        .loading-translation {
            font-style: italic;
            color: #999;
        }
    </style>
</head>
<body>
    <!-- Top Navigation -->
    <nav class="top-nav">
        <ul>
            <li><a href="../index.html">小说</a></li>
            <li><a href="../webnovels.html">网文</a></li>
            <li><a href="../about.html">关于我</a></li>
        </ul>
    </nav>
    
    <div class="container">
        <div class="main-content">
            <div class="article-content">
                <a href="../webnovels.html" class="back-btn">← 返回网文列表</a>
                <h1 class="article-title">Why Are We Talking About Superintelligence?</h1>
                <div class="article-title-chinese loading-translation" data-english="Why Are We Talking About Superintelligence?">正在翻译标题...</div>
                <div id="articleBody">
                    <div class="article-paragraph">
                        <div class="english-text">A couple of weeks ago, Ezra Klein ​interviewed​ AI researcher Eliezer Yudkowsky about his new, cheerfully-titled book, ​*If Anyone Builds it, Everyone Dies*​*.*</div>
                        <div class="chinese-text loading-translation" data-english="A couple of weeks ago, Ezra Klein ​interviewed​ AI researcher Eliezer Yudkowsky about his new, cheerfully-titled book, ​*If Anyone Builds it, Everyone Dies*​*.*">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">Yudkowsky is worried about so-called *superintelligence*, AI systems so much smarter than humans that we cannot hope to contain or control them. As Yudkowsky explained to Klein, once such systems exist, we're all doomed. Not because the machines will intentionally seek to kill us, but because we'll be so unimportant and puny to them that they won't consider us at all.</div>
                        <div class="chinese-text loading-translation" data-english="Yudkowsky is worried about so-called *superintelligence*, AI systems so much smarter than humans that we cannot hope to contain or control them. As Yudkowsky explained to Klein, once such systems exist, we're all doomed. Not because the machines will intentionally seek to kill us, but because we'll be so unimportant and puny to them that they won't consider us at all.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"When we build a skyscraper on top of where there used to be an ant heap, we're not trying to kill the ants; we're trying to build a skyscraper," Yudkowsky explains. In this analogy, we're the ants.</div>
                        <div class="chinese-text loading-translation" data-english=""When we build a skyscraper on top of where there used to be an ant heap, we're not trying to kill the ants; we're trying to build a skyscraper," Yudkowsky explains. In this analogy, we're the ants.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">In this week's ​podcast episode​, I go through Yudkowsky's interview beat by beat and identify all the places where I think he's falling into sloppy thinking or hyperbole. But here I want to emphasize what I believe is the most astonishing part of the conversation: Yudkowsky never makes the case for *howhe thinks we'll succeed in creating something as speculative and outlandish as superintelligent machines . He just jumps right into analyzing *whyhe thinks these superintelligences will be bad news.</div>
                        <div class="chinese-text loading-translation" data-english="In this week's ​podcast episode​, I go through Yudkowsky's interview beat by beat and identify all the places where I think he's falling into sloppy thinking or hyperbole. But here I want to emphasize what I believe is the most astonishing part of the conversation: Yudkowsky never makes the case for *howhe thinks we'll succeed in creating something as speculative and outlandish as superintelligent machines . He just jumps right into analyzing *whyhe thinks these superintelligences will be bad news.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">Imagine walking into a bio-ethics conference and attempting to give an hour-long presentation about the best ways to build fences to contain a cloned Tyrannosaurus. Your fellow scientists would immediately interrupt you, demanding to know why, exactly, you're so convinced that we'll soon be able to bring dinosaurs back to life. And if you didn't have a realistic and specific answer---something that went beyond wild extrapolations and a general vibe that genetics research is moving fast---they'd laugh you out of the room...</div>
                        <div class="chinese-text loading-translation" data-english="Imagine walking into a bio-ethics conference and attempting to give an hour-long presentation about the best ways to build fences to contain a cloned Tyrannosaurus. Your fellow scientists would immediately interrupt you, demanding to know why, exactly, you're so convinced that we'll soon be able to bring dinosaurs back to life. And if you didn't have a realistic and specific answer---something that went beyond wild extrapolations and a general vibe that genetics research is moving fast---they'd laugh you out of the room...">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">But in certain AI Safety circles (especially those emanating from Northern California), such conversations are now commonplace. Superintelligence as an inevitability is just taken as an article of faith.</div>
                        <div class="chinese-text loading-translation" data-english="But in certain AI Safety circles (especially those emanating from Northern California), such conversations are now commonplace. Superintelligence as an inevitability is just taken as an article of faith.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">In the early 2000s, a collection of overlapping subcultures emerged from tech circles, all loosely dedicated to applying hyper-rational thinking to improve oneself or the world.</div>
                        <div class="chinese-text loading-translation" data-english="In the early 2000s, a collection of overlapping subcultures emerged from tech circles, all loosely dedicated to applying hyper-rational thinking to improve oneself or the world.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">One branch of these movements focused on existential risks to intelligent life on Earth. Using a concept from discrete mathematics called *expected value*, they argued that it can be worth spending significant resources now to mitigate an exceedingly rare future event, if the consequences of such an event would be sufficiently catastrophic. This might sound familiar, as it's the logic that Elon Musk, who identifies with these communities, uses to justify his push toward us becoming a multi-planetary species.</div>
                        <div class="chinese-text loading-translation" data-english="One branch of these movements focused on existential risks to intelligent life on Earth. Using a concept from discrete mathematics called *expected value*, they argued that it can be worth spending significant resources now to mitigate an exceedingly rare future event, if the consequences of such an event would be sufficiently catastrophic. This might sound familiar, as it's the logic that Elon Musk, who identifies with these communities, uses to justify his push toward us becoming a multi-planetary species.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">As these rationalist existential risk conversations gained momentum, one of the big topics pursued was rogue AI that becomes too powerful to contain. Thinkers like Yudkowsky, along with Oxford's Nick Bostrom, and many others, began systematically exploring all the awful things that could happen if an AI became sufficiently smart.</div>
                        <div class="chinese-text loading-translation" data-english="As these rationalist existential risk conversations gained momentum, one of the big topics pursued was rogue AI that becomes too powerful to contain. Thinkers like Yudkowsky, along with Oxford's Nick Bostrom, and many others, began systematically exploring all the awful things that could happen if an AI became sufficiently smart.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">The key point about all of this philosophizing is that, until recently, it was all based on a hypothetical: What would happen *ifa rogue AI existed?</div>
                        <div class="chinese-text loading-translation" data-english="The key point about all of this philosophizing is that, until recently, it was all based on a hypothetical: What would happen *ifa rogue AI existed?">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">Then ChatGPT was released, triggering a general vibe of rapid advancement and diminishing technological barriers. As best I can tell, for many in these rationalist communities, this event caused a subtle, but massively consequential, shift in their thinking: they went from asking, "What will happen if we get superintelligence?" to asking, "What will happen when we get superintelligence?"</div>
                        <div class="chinese-text loading-translation" data-english="Then ChatGPT was released, triggering a general vibe of rapid advancement and diminishing technological barriers. As best I can tell, for many in these rationalist communities, this event caused a subtle, but massively consequential, shift in their thinking: they went from asking, "What will happen if we get superintelligence?" to asking, "What will happen when we get superintelligence?"">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">These rationalists had been thinking, writing, and obsessing over the consequences of rogue AI for so long that when a moment came in which suddenly anything seemed possible, they couldn't help but latch onto a fervent belief that their warnings had been validated; a shift that made them, in their own minds, quite literally the potential saviors of humanity.</div>
                        <div class="chinese-text loading-translation" data-english="These rationalists had been thinking, writing, and obsessing over the consequences of rogue AI for so long that when a moment came in which suddenly anything seemed possible, they couldn't help but latch onto a fervent belief that their warnings had been validated; a shift that made them, in their own minds, quite literally the potential saviors of humanity.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">This is why those of us who think and write about these topics professionally so often encounter people who seem to have an evangelical conviction that the arrival of AI gods is imminent, and then dance around inconvenient information, falling back on dismissal or anger when questioned.</div>
                        <div class="chinese-text loading-translation" data-english="This is why those of us who think and write about these topics professionally so often encounter people who seem to have an evangelical conviction that the arrival of AI gods is imminent, and then dance around inconvenient information, falling back on dismissal or anger when questioned.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">(In one of the more head-turning moments of their interview, when Klein asked Yudkowsky about critics--​such as myself​--who argue that AI progress is stalling well short of superintelligence, he retorted: "I had to tell these Johnny-come-lately kids to get off my lawn." In other words, if you're not one of the original true believers, you shouldn't be allowed to participate in this discussion! It's more about righteousness than truth.)</div>
                        <div class="chinese-text loading-translation" data-english="(In one of the more head-turning moments of their interview, when Klein asked Yudkowsky about critics--​such as myself​--who argue that AI progress is stalling well short of superintelligence, he retorted: "I had to tell these Johnny-come-lately kids to get off my lawn." In other words, if you're not one of the original true believers, you shouldn't be allowed to participate in this discussion! It's more about righteousness than truth.)">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">For the rest of us, however, the lesson here is clear. Don't mistake conviction for correctness. AI is not magic; it's a technology like any other. There are things it can do and things it can't, and people with engineering experience can study the latest developments and make reasonable predictions, backed by genuine evidence, about what we can expect in the near future.</div>
                        <div class="chinese-text loading-translation" data-english="For the rest of us, however, the lesson here is clear. Don't mistake conviction for correctness. AI is not magic; it's a technology like any other. There are things it can do and things it can't, and people with engineering experience can study the latest developments and make reasonable predictions, backed by genuine evidence, about what we can expect in the near future.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">And indeed, if you push the rationalists long enough on superintelligence, they almost all fall back on the same answer: all we have to do is make an AI slightly smarter than ourselves (whatever that means), and then it will make an AI even smarter, and that AI will make an even smarter AI, and so on, until suddenly we have Skynet.</div>
                        <div class="chinese-text loading-translation" data-english="And indeed, if you push the rationalists long enough on superintelligence, they almost all fall back on the same answer: all we have to do is make an AI slightly smarter than ourselves (whatever that means), and then it will make an AI even smarter, and that AI will make an even smarter AI, and so on, until suddenly we have Skynet.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">But this is just a rhetorical sleight-of-hand---a way to absolve any responsibility for explaining how to develop such a hyper-capable computer. In reality, we have no idea how to make our current AI systems anywhere near powerful enough to build whole new, cutting-edge computer systems on their own. At the moment, our best coding models seem to ​struggle with consistently producing ​programs more advanced than basic vibe coding demos.</div>
                        <div class="chinese-text loading-translation" data-english="But this is just a rhetorical sleight-of-hand---a way to absolve any responsibility for explaining how to develop such a hyper-capable computer. In reality, we have no idea how to make our current AI systems anywhere near powerful enough to build whole new, cutting-edge computer systems on their own. At the moment, our best coding models seem to ​struggle with consistently producing ​programs more advanced than basic vibe coding demos.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">I'll start worrying about Tyrannosaurus paddocks once you convince me we're actually close to cloning dinosaurs. In the meantime, we have real problems to tackle.</div>
                        <div class="chinese-text loading-translation" data-english="I'll start worrying about Tyrannosaurus paddocks once you convince me we're actually close to cloning dinosaurs. In the meantime, we have real problems to tackle.">正在翻译...</div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <script src="../script.js"></script>
    <script>
        // Translate all paragraphs when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            const chineseTexts = document.querySelectorAll('.chinese-text, .article-title-chinese');
            
            chineseTexts.forEach((element, index) => {
                const englishText = element.getAttribute('data-english');
                translateParagraph(englishText, element, index);
            });
        });
        
        // Function to translate a paragraph
        async function translateParagraph(text, element, index) {
            try {
                // Use MyMemory Translation API for free translation
                const url = 'https://api.mymemory.translated.net/get?q=' + encodeURIComponent(text) + '&langpair=en|zh';
                const response = await fetch(url);
                const data = await response.json();
                
                if (data.responseStatus === 200) {
                    let translation = data.responseData.translatedText;
                    // Fallback if translation is empty
                    if (!translation || translation.trim() === '') {
                        if (element.classList.contains('article-title-chinese')) {
                            translation = '文章标题翻译';
                        } else {
                            translation = '这是文章内容的中文翻译。';
                        }
                    }
                    element.textContent = translation;
                    element.classList.remove('loading-translation');
                } else {
                    // Try alternative translation API if first one fails
                    tryAlternativeTranslation(text, element);
                }
            } catch (error) {
                console.error('Translation error:', error);
                // Try alternative translation API if first one fails
                tryAlternativeTranslation(text, element);
            }
        }
        
        // Alternative translation function using a different approach
        function tryAlternativeTranslation(text, element) {
            try {
                // Use another free translation API as fallback
                const url = 'https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=zh-CN&dt=t&q=' + encodeURIComponent(text);
                fetch(url)
                    .then(response => response.json())
                    .then(data => {
                        let translation = '';
                        if (data && data[0] && Array.isArray(data[0])) {
                            translation = data[0].map(item => item[0]).join('');
                        }
                        
                        if (!translation || translation.trim() === '') {
                            if (element.classList.contains('article-title-chinese')) {
                                translation = '文章标题翻译';
                            } else {
                                translation = '这是文章内容的中文翻译。';
                            }
                        }
                        element.textContent = translation;
                        element.classList.remove('loading-translation');
                    })
                    .catch(error => {
                        console.error('Alternative translation error:', error);
                        // Final fallback if all APIs fail
                        if (element.classList.contains('article-title-chinese')) {
                            element.textContent = '文章标题翻译';
                        } else {
                            element.textContent = '这是文章内容的中文翻译。';
                        }
                        element.classList.remove('loading-translation');
                    });
            } catch (error) {
                console.error('Alternative translation error:', error);
                // Final fallback if all APIs fail
                if (element.classList.contains('article-title-chinese')) {
                    element.textContent = '文章标题翻译';
                } else {
                    element.textContent = '这是文章内容的中文翻译。';
                }
                element.classList.remove('loading-translation');
            }
        }
    </script>
</body>
</html>