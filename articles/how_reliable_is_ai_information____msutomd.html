<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How reliable is AI information? - English Novel Reader</title>
    <link rel="stylesheet" href="../styles.css">
    <style>
        /* Article reader specific styles */
        .article-content {
            max-width: 800px;
            margin: 100px auto;
            padding: 30px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        
        .article-title {
            font-size: 1.8rem;
            color: #5a3e2b;
            margin-bottom: 10px;
            font-family: Georgia, serif;
        }
        
        .article-title-chinese {
            font-size: 1.2rem;
            color: #666;
            margin-bottom: 30px;
            font-family: 'Microsoft YaHei', sans-serif;
            opacity: 0.8;
        }
        
        .article-paragraph {
            margin-bottom: 25px;
            line-height: 1.8;
        }
        
        .english-text {
            font-family: Georgia, serif;
            font-size: 1.1rem;
            color: #333;
            margin-bottom: 15px;
        }
        
        .chinese-text {
            font-family: 'Microsoft YaHei', sans-serif;
            font-size: 1rem;
            color: #666;
            opacity: 0.7;
            margin-bottom: 30px;
            padding-left: 20px;
            border-left: 3px solid #d4a76a;
        }
        
        .back-btn {
            display: inline-block;
            background-color: #5a3e2b;
            color: #fff;
            padding: 10px 20px;
            border-radius: 6px;
            text-decoration: none;
            font-family: 'Microsoft YaHei', sans-serif;
            font-size: 1rem;
            transition: all 0.3s ease;
            margin-bottom: 30px;
        }
        
        .back-btn:hover {
            background-color: #7a5c42;
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        
        .loading-translation {
            font-style: italic;
            color: #999;
        }
    </style>
</head>
<body>
    <!-- Top Navigation -->
    <nav class="top-nav">
        <ul>
            <li><a href="../index.html">小说</a></li>
            <li><a href="../webnovels.html">网文</a></li>
            <li><a href="../about.html">关于我</a></li>
        </ul>
    </nav>
    
    <div class="container">
        <div class="main-content">
            <div class="article-content">
                <a href="../webnovels.html" class="back-btn">← 返回网文列表</a>
                <h1 class="article-title">How reliable is AI information?</h1>
                <div class="article-title-chinese loading-translation" data-english="How reliable is AI information?">正在翻译标题...</div>
                <div id="articleBody">
                    <div class="article-paragraph">
                        <div class="english-text">While artificial intelligence, or AI, tools like ChatGPT might be great for helping you pick where to go for dinner or which TV show to binge watch, would you trust it to make decisions about your medical care or finances?</div>
                        <div class="chinese-text loading-translation" data-english="While artificial intelligence, or AI, tools like ChatGPT might be great for helping you pick where to go for dinner or which TV show to binge watch, would you trust it to make decisions about your medical care or finances?">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">AI tools like ChatGPT and Gemini include a disclaimer that the information they find scanning the internet may not always be accurate. If someone was researching a topic that they didn't know anything about, how would they know how to confirm the information as truth? As AI tools become smarter and gain more widespread use in daily life, so do the stakes for the accuracy and dependability of using this evolving technology.</div>
                        <div class="chinese-text loading-translation" data-english="AI tools like ChatGPT and Gemini include a disclaimer that the information they find scanning the internet may not always be accurate. If someone was researching a topic that they didn't know anything about, how would they know how to confirm the information as truth? As AI tools become smarter and gain more widespread use in daily life, so do the stakes for the accuracy and dependability of using this evolving technology.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">Michigan State University researchers aim to increase the reliability of AI information. To do this, they have developed a new method that acts like a trust meter and reports the accuracy of information produced from AI large language models, or LLMs.</div>
                        <div class="chinese-text loading-translation" data-english="Michigan State University researchers aim to increase the reliability of AI information. To do this, they have developed a new method that acts like a trust meter and reports the accuracy of information produced from AI large language models, or LLMs.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">Reza Khan Mohammadi, a doctoral student in MSU's ++College of Engineering++, and ++Mohammad Ghassemi++, an assistant professor in the Department of Computer Science and Engineering, collaborated with researchers from Henry Ford Health and JPMorganChase Artificial Intelligence Research on this work.</div>
                        <div class="chinese-text loading-translation" data-english="Reza Khan Mohammadi, a doctoral student in MSU's ++College of Engineering++, and ++Mohammad Ghassemi++, an assistant professor in the Department of Computer Science and Engineering, collaborated with researchers from Henry Ford Health and JPMorganChase Artificial Intelligence Research on this work.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"As more people rely on LLMs in their daily work, there's a fundamental question of trust that lingers in the back of our minds: Is the information we're getting actually correct?" said Khan Mohammadi. "Our goal was to create a practical 'trust meter' that could give users a clear signal of the model's true confidence, especially in high-stakes domains where an error can have serious consequences."
 The CCPS method questions AI to see how confident the answer is. Credit: Reza Khan Mohammadi/Michigan State University</div>
                        <div class="chinese-text loading-translation" data-english=""As more people rely on LLMs in their daily work, there's a fundamental question of trust that lingers in the back of our minds: Is the information we're getting actually correct?" said Khan Mohammadi. "Our goal was to create a practical 'trust meter' that could give users a clear signal of the model's true confidence, especially in high-stakes domains where an error can have serious consequences."
 The CCPS method questions AI to see how confident the answer is. Credit: Reza Khan Mohammadi/Michigan State University">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">Though a person can repeatedly ask an AI tool the same question to check for consistency --- a slow and energy costly process --- the MSU-led team developed a more efficient internal approach. The new method called Calibrating LLM Confidence by Probing Perturbed Representation Stability, or CCPS, applies tiny nudges to an LLM's internal state while it's forming an answer. These nudges "poke" at the foundation of the answer to see if the answer is strong and stable or weak and unreliable.</div>
                        <div class="chinese-text loading-translation" data-english="Though a person can repeatedly ask an AI tool the same question to check for consistency --- a slow and energy costly process --- the MSU-led team developed a more efficient internal approach. The new method called Calibrating LLM Confidence by Probing Perturbed Representation Stability, or CCPS, applies tiny nudges to an LLM's internal state while it's forming an answer. These nudges "poke" at the foundation of the answer to see if the answer is strong and stable or weak and unreliable.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"The idea is simple but powerful, and if small internal changes cause the model's potential answer to shift, it probably wasn't very confident to begin with," said Ghassemi. "A genuinely confident decision should be stable and resilient, like a well-built bridge. We essentially test that bridge's integrity."</div>
                        <div class="chinese-text loading-translation" data-english=""The idea is simple but powerful, and if small internal changes cause the model's potential answer to shift, it probably wasn't very confident to begin with," said Ghassemi. "A genuinely confident decision should be stable and resilient, like a well-built bridge. We essentially test that bridge's integrity."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">The researchers have found that their method is significantly better at predicting when an LLM is correct. Compared to the strongest prior techniques, the CCPS method cuts the calibration error --- the gap between an AI's expressed confidence and its actual accuracy --- by more than half on average.</div>
                        <div class="chinese-text loading-translation" data-english="The researchers have found that their method is significantly better at predicting when an LLM is correct. Compared to the strongest prior techniques, the CCPS method cuts the calibration error --- the gap between an AI's expressed confidence and its actual accuracy --- by more than half on average.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">"The CCPS method has profound clinical implications because it addresses the primary safety barrier for LLMs in medicine, which is their tendency to state errors with high confidence," said Kundan Thind, co-author on the paper and division head of radiation oncology physics with Henry Ford Cancer Institute. "This method improves an LLM's internal confidence calibration, enabling the model to reliably 'know when it doesn't know' and defer to human expert judgment."</div>
                        <div class="chinese-text loading-translation" data-english=""The CCPS method has profound clinical implications because it addresses the primary safety barrier for LLMs in medicine, which is their tendency to state errors with high confidence," said Kundan Thind, co-author on the paper and division head of radiation oncology physics with Henry Ford Cancer Institute. "This method improves an LLM's internal confidence calibration, enabling the model to reliably 'know when it doesn't know' and defer to human expert judgment."">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">This breakthrough has been tested on high-stakes examples in medical and financial question-answering, and its potential to enhance safety and trust in AI is vast.</div>
                        <div class="chinese-text loading-translation" data-english="This breakthrough has been tested on high-stakes examples in medical and financial question-answering, and its potential to enhance safety and trust in AI is vast.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">This research was recently presented at the Conference on Empirical Methods in Natural Language Processing in China, where it was nominated for an Outstanding Paper Award --- a distinction placing the work in the top 0.4% of more than 8,000 submissions to the conference.</div>
                        <div class="chinese-text loading-translation" data-english="This research was recently presented at the Conference on Empirical Methods in Natural Language Processing in China, where it was nominated for an Outstanding Paper Award --- a distinction placing the work in the top 0.4% of more than 8,000 submissions to the conference.">正在翻译...</div>
                    </div>
                    <div class="article-paragraph">
                        <div class="english-text">Research funding was provided by the ++Henry Ford Health + Michigan State University Health Sciences Cancer Seed Funding Program++ and by the JPMorganChase Artificial Intelligence Research Faculty Research Award.</div>
                        <div class="chinese-text loading-translation" data-english="Research funding was provided by the ++Henry Ford Health + Michigan State University Health Sciences Cancer Seed Funding Program++ and by the JPMorganChase Artificial Intelligence Research Faculty Research Award.">正在翻译...</div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <script src="../script.js"></script>
    <script>
        // Translate all paragraphs when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            const chineseTexts = document.querySelectorAll('.chinese-text, .article-title-chinese');
            
            chineseTexts.forEach((element, index) => {
                const englishText = element.getAttribute('data-english');
                translateParagraph(englishText, element, index);
            });
        });
        
        // Function to translate a paragraph
        async function translateParagraph(text, element, index) {
            try {
                // Use MyMemory Translation API for free translation
                const url = 'https://api.mymemory.translated.net/get?q=' + encodeURIComponent(text) + '&langpair=en|zh';
                const response = await fetch(url);
                const data = await response.json();
                
                if (data.responseStatus === 200) {
                    let translation = data.responseData.translatedText;
                    // Fallback if translation is empty
                    if (!translation || translation.trim() === '') {
                        if (element.classList.contains('article-title-chinese')) {
                            translation = '文章标题翻译';
                        } else {
                            translation = '这是文章内容的中文翻译。';
                        }
                    }
                    element.textContent = translation;
                    element.classList.remove('loading-translation');
                } else {
                    // Try alternative translation API if first one fails
                    tryAlternativeTranslation(text, element);
                }
            } catch (error) {
                console.error('Translation error:', error);
                // Try alternative translation API if first one fails
                tryAlternativeTranslation(text, element);
            }
        }
        
        // Alternative translation function using a different approach
        function tryAlternativeTranslation(text, element) {
            try {
                // Use another free translation API as fallback
                const url = 'https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=zh-CN&dt=t&q=' + encodeURIComponent(text);
                fetch(url)
                    .then(response => response.json())
                    .then(data => {
                        let translation = '';
                        if (data && data[0] && Array.isArray(data[0])) {
                            translation = data[0].map(item => item[0]).join('');
                        }
                        
                        if (!translation || translation.trim() === '') {
                            if (element.classList.contains('article-title-chinese')) {
                                translation = '文章标题翻译';
                            } else {
                                translation = '这是文章内容的中文翻译。';
                            }
                        }
                        element.textContent = translation;
                        element.classList.remove('loading-translation');
                    })
                    .catch(error => {
                        console.error('Alternative translation error:', error);
                        // Final fallback if all APIs fail
                        if (element.classList.contains('article-title-chinese')) {
                            element.textContent = '文章标题翻译';
                        } else {
                            element.textContent = '这是文章内容的中文翻译。';
                        }
                        element.classList.remove('loading-translation');
                    });
            } catch (error) {
                console.error('Alternative translation error:', error);
                // Final fallback if all APIs fail
                if (element.classList.contains('article-title-chinese')) {
                    element.textContent = '文章标题翻译';
                } else {
                    element.textContent = '这是文章内容的中文翻译。';
                }
                element.classList.remove('loading-translation');
            }
        }
    </script>
</body>
</html>