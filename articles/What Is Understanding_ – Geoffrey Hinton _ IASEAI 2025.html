<!DOCTYPE html>

<html lang="zh">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Untitled - English Novel Reader</title>
<link href="../styles.css" rel="stylesheet"/>
<style>
        body {
            font-family: Georgia, serif;
            background-color: #f9f7f4;
            margin: 0;
            padding: 0;
        }
        
        .article-content {
            max-width: 900px;
            margin: 100px auto 50px;
            padding: 40px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        
        .back-btn {
            display: inline-block;
            background-color: #5a3e2b;
            color: #fff;
            padding: 10px 20px;
            border-radius: 6px;
            text-decoration: none;
            font-family: 'Microsoft YaHei', sans-serif;
            font-size: 0.95rem;
            transition: all 0.3s ease;
            margin-bottom: 30px;
        }
        
        .back-btn:hover {
            background-color: #7a5c42;
            transform: translateY(-2px);
        }
        
        .article-title {
            font-family: Georgia, serif;
            font-size: 2rem;
            color: #2c2c2c;
            margin-bottom: 30px;
            line-height: 1.3;
            font-weight: 600;
        }
        
        .article-section {
            margin-bottom: 30px;
        }
        
        .section-heading {
            font-family: Georgia, serif;
            font-size: 1.5rem;
            color: #3a3a3a;
            margin-top: 35px;
            margin-bottom: 20px;
            font-weight: 600;
            line-height: 1.4;
        }
        
        .section-subheading {
            font-family: Georgia, serif;
            font-size: 1.2rem;
            color: #4a4a4a;
            margin-top: 25px;
            margin-bottom: 15px;
            font-weight: 600;
            line-height: 1.4;
        }
        
        .paragraph-block {
            margin-bottom: 25px;
        }
        
        .english-text {
            font-family: Georgia, serif;
            font-size: 1.1rem;
            color: #2c2c2c;
            line-height: 1.8;
            margin-bottom: 12px;
        }
        
        .chinese-text {
            font-family: 'Microsoft YaHei', 'SimHei', sans-serif;
            font-size: 1rem;
            color: #666;
            line-height: 1.8;
            padding-left: 20px;
            border-left: 3px solid #d4a76a;
            opacity: 0.7;
        }
        
        @media (max-width: 768px) {
            .article-content {
                margin: 80px 15px 30px;
                padding: 25px;
            }
            
            .article-title {
                font-size: 1.6rem;
            }
            
            .section-heading {
                font-size: 1.3rem;
            }
            
            .english-text {
                font-size: 1rem;
            }
        }
    </style>
</head>
<body>
<!-- Top Navigation -->
<nav class="top-nav">
<ul>
<li><a href="../index.html">首页</a></li>
<li><a href="../novels.html">小说</a></li>
<li><a class="active" href="../webnovels.html">网文</a></li>
    <li><a href="../news.html">新闻</a></li>
    <li><a href="../about.html">关于我</a></li>
</ul>
</nav>
<div class="article-content">
<a class="back-btn" href="../webnovels.html">← 返回网文列表</a>
<h1 class="article-title">Untitled</h1>
<div class="paragraph-block">
<p class="english-text">00:00:00
[Applause] So today I'm going to talk about what understanding is. We need the scientific community to agree on what understanding is. If you think about the first step in tackling climate change, we had to reach a scientific consensus on what was causing it before we could advise on what to do about it. Now with these large language models, chatbots, there's still many scientists who don't think that they really understand the same way as we do. They believe in a very different model of what human</p>
<p class="chinese-text">00:00:00
[鼓掌]所以今天我要讲什么是理解。我们需要科学界就理解是什么达成一致。如果你考虑应对气候变化的第一步，我们必须就气候变化的原因达成科学共识，然后才能就如何应对气候变化提出建议。现在有了这些大型语言模型、聊天机器人，仍然有许多科学家认为他们的理解方式与我们不同。他们相信一种与人类截然不同的模式</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:00:34
understanding is. For the last 70 years, there've been two very different paradigms for intelligence. The logic inspired paradigm which dominated for about the first 50 years of AI is that the essence of intelligence is reasoning. And reasoning is done by using symbolic rules to manipulate symbolic expressions. So your knowledge is a bunch of symbolic expressions inside your head. They thought learning could wait. The first thing we have to understand is how knowledge is represented. It's some</p>
<p class="chinese-text">00:00:34
理解岛。在过去的 70 年里，出现了两种截然不同的智力范式。在人工智能的前 50 年中占主导地位的逻辑启发范式是，智能的本质是推理。推理是通过使用符号规则来操纵符号表达式来完成的。所以你的知识是你头脑中的一堆符号表达。他们认为学习可以等待。我们首先要了解的是知识是如何表示的。是一些</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:01:04
special logically unamiguous language. And figuring out how knowledge is represented has to come first. The contrast was a biologically inspired approach. That's what people like Turing and Fonoman believed in. And there the essence of intelligence is learning the strengths of the connections in a neural network. And those people think that reasoning can wait. First we have to understand how learning works and later on we'll understand reasoning. Reasoning is something that came very late</p>
<p class="chinese-text">00:01:04
特殊的逻辑明确的语言。必须首先弄清楚知识是如何表示的。对比是一种受生物学启发的方法。这就是图灵和福诺曼等人所相信的。智能的本质是学习神经网络中连接的强度。而那些人则认为推理可以等待。首先我们必须了解学习是如何进行的，然后我们将了解推理。推理是来得很晚的事情</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:01:31
biologically. So the real transition to most people believing in the biological approach rather than the logical approach came in 2012 when a deep neural network trained with back propagation got about half the error rate of standard computer vision systems which have been highly tuned for this competition the imageet competition. Once that happened, then the whole computer vision community fairly rapidly switched to um using neural nets and that opened the floodgates for what we see now, which is</p>
<p class="chinese-text">00:01:31
从生物学上来说。因此，大多数人真正相信生物学方法而不是逻辑方法的转变发生在 2012 年，当时经过反向传播训练的深度神经网络的错误率约为标准计算机视觉系统的一半，而标准计算机视觉系统已针对图像组竞赛进行了高度调整。一旦发生这种情况，整个计算机视觉社区很快就转向使用神经网络，这为我们现在所看到的打开了闸门，即</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:02:08
neural nets being used for everything. So now what people mean by AI is artificial neural networks. For a long long time, what they meant by AI was definitely not artificial neural networks. It was um symbolic AI. But even when we could do vision better than standard symbolic AI, many people in the symbolic AI community said, "Yeah, but they'll never do language." Because obviously if symbolic AI is going to be good for anything, it's going to be good for language because that is strings of</p>
<p class="chinese-text">00:02:08
神经网络被用于一切。所以现在人们所说的AI就是人工神经网络。很长一段时间，他们所说的AI绝对不是人工神经网络。这是嗯象征性的人工智能。但即使我们可以比标准符号人工智能做得更好，符号人工智能社区中的许多人也会说：“是的，但他们永远不会做语言。”因为显然，如果符号人工智能对任何事情都有好处，那么它也会对语言有好处，因为那是字符串</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:02:37
symbols in and strings of symbols out. The linguists were also very skeptical. So most linguists believed in Chsky's theory, which I think is crazy, um that language is not learned. I think Chsk is sort of a cult leader. If you can get people to agree on something that's manifest nonsense that language is not learned, then you've got them. Now, Chsky never had a theory of meaning. It was all about syntax. He didn't sort of know how to have a theory of meaning. And for the linguist, the idea that a</p>
<p class="chinese-text">00:02:37
符号输入和符号串输出。语言学家也非常怀疑。所以大多数语言学家都相信 Chsky 的理论，我认为这很疯狂，嗯，语言不是习得的。我认为 Chsk 有点像邪教领袖。如果你能让人们就语言不是学来的明显无稽之谈达成一致，那么你就成功了。现在，查斯基从未有过意义理论。这都是关于语法的。他有点不知道如何建立意义理论。对于语言学家来说，这个想法</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:03:08
big neural network with random weights and no innate knowledge could actually learn both syntax and semantics um just by looking at data was real anathema. They were very confident that could never happen. Chsky was so confident that even after it had happened, he published articles saying, "Well, they'd never be able to do this," without actually checking and asking them to do that, which they did very well. So, here's two very different theories of the meaning of a word. And for a long</p>
<p class="chinese-text">00:03:08
具有随机权重且没有先天知识的大型神经网络实际上可以通过查看数据来学习语法和语义，这真是令人厌恶。他们非常有信心这永远不会发生。切斯基非常自信，甚至在事情发生之后，他发表文章说，“好吧，他们永远无法做到这一点”，而没有实际检查并要求他们这样做，而他们做得很好。因此，这是关于单词含义的两种截然不同的理论。并且在很长一段时间里</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:03:36
time, it looked as though these two theories were just alternative theories of meaning. The symbolic AI theory is that the meaning of a word comes from its relationships to other words. So what a verb means is determined by how it occurs with these other words in sentences. And to capture meaning, we need something like a relational graph where you have words, you have links between them, you have the relationship attached to the link, and that's how you're going to represent meaning, a knowledge graph</p>
<p class="chinese-text">00:03:36
当时，这两种理论似乎只是意义的替代理论。符号人工智能理论认为，一个词的意义来自于它与其他词的关系。因此，动词的含义取决于它与句子中其他单词的出现方式。为了捕捉意义，我们需要像关系图这样的东西，其中有单词，它们之间有链接，有附加到链接的关系，这就是你将如何表示意义，知识图</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:04:06
of some kind. Psychologists, particularly in the 1930s, I think, thought that the meaning of a word is actually just a big set of semantic features. There might also be syntactic features and the words with similar meanings have similar semantic features. So Tuesday and Wednesday will have very similar sets of semantic features whereas Tuesday and although will have very different sets of semantic features and syntactic features. In 1985 I made a tiny language model that tried to unify those two</p>
<p class="chinese-text">00:04:06
某种。我认为，心理学家，特别是 20 世纪 30 年代的心理学家，认为一个词的含义实际上只是一大组语义特征。也可能存在句法特征，并且具有相似含义的单词具有相似的语义特征。因此，星期二和星期三将具有非常相似的语义特征集，而星期二和尽管将具有非常不同的语义特征和句法特征集。1985 年，我制作了一个小型语言模型，试图将这两者统一起来</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:04:36
theories. So the idea was you would learn semantic features for each word symbol and you'd learn how to make all those features of the previous words interact to predict the features of the next word. The model was trained by back propagation to predict the next word. So that's just like these large large language models today. And like those models today, instead of storing sentences or propositions like the symbolic eye people thought you ought to, it would actually not store any sentences or any propositions. It would</p>
<p class="chinese-text">00:04:36
理论。因此，我们的想法是，您将学习每个单词符号的语义特征，并且您将学习如何使前面单词的所有这些特征相互作用以预测下一个单词的特征。该模型通过反向传播进行训练来预测下一个单词。这就像今天的大型语言模型一样。就像今天的那些模型一样，它实际上不会存储任何句子或任何命题，而不是像人们认为应该存储的象征性眼睛那样存储句子或命题。它会</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:05:09
generate sentences by repeatedly predicting the next word when it wanted to generate a sentence. There were no sentences inside. The knowledge it had was relational knowledge that resided in the way features of words interacted so as to predict the features of the next word. That's very different from a bunch of propositions and rules for manipulating them. If you ask what happened over the next 30 years, about 10 years after that tiny language model, which is really tiny, it only had a few</p>
<p class="chinese-text">00:05:09
当它想要生成句子时，通过重复预测下一个单词来生成句子。里面没有任何句子。它拥有的知识是关系知识，存在于单词特征相互作用的方式中，从而预测下一个单词的特征。这与一堆操纵它们的命题和规则非常不同。如果你问接下来的 30 年发生了什么，大约 10 年后发生了那个微小的语言模型，它真的很小，它只有几个</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:05:35
thousand weights. Yoshu Benjio showed that you could actually use similar kinds of models for predicting the next word in real natural language. So you could model what was going on in natural language with this kind of model. And it was about the same as the state-of-the-art. About 10 years after that, leading computational linguists began to accept that feature vectors, which they called embeddings, were actually a good way to model meanings of words. And about 10 years after that, researchers at Google</p>
<p class="chinese-text">00:05:35
千重。Yoshu Benjio 表明，您实际上可以使用类似的模型来预测真实自然语言中的下一个单词。所以你可以用这种模型来模拟自然语言中发生的事情。它与最先进的技术大致相同。大约十年后，领先的计算语言学家开始接受特征向量（他们称之为嵌入）实际上是对单词含义进行建模的好方法。大约十年后，谷歌的研究人员</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:06:06
invented transformers and published them. And OpenAI then used them and showed the world what they could do. And that's when people not just researchers but everybody began to get interested in what was happening in these large language models. Were they really understanding what they were saying? So the large language models can be viewed particularly by me as descendants of the tiny language model. They use many more words as input. They have big contexts. They use many more layers of neurons so that they can</p>
<p class="chinese-text">00:06:06
发明了变压器并出版了它们。然后 OpenAI 使用它们并向世界展示了它们的能力。从那时起，人们不仅是研究人员，而且每个人都开始对这些大型语言模型中发生的事情感兴趣。他们真的明白自己在说什么吗？因此，我可以特别将大型语言模型视为小型语言模型的后代。他们使用更多的单词作为输入。他们有很大的背景。他们使用更多层的神经元，这样他们就可以</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:06:38
disambiguate words as they go through the net. A word like may initially you represent it with some feature vector that's sort of hedging its bets between whether it's a month or a modal or a woman's name. As you go through the net, you use interactions with the context to clean it up into one of those three meanings. They use much more complicated interactions between the learned features. In the original tiny language model, the interaction is very simple. In current large language models,</p>
<p class="chinese-text">00:06:38
当单词通过网络时消除歧义。像这样的词最初可能会用一些特征向量来表示它，该向量在月份、情态动词或女性名字之间进行了对冲。当您浏览网络时，您可以使用与上下文的交互将其清理为这三种含义之一。他们在学习到的特征之间使用更复杂的交互。在最初的微型语言模型中，交互非常简单。在目前的大型语言模型中，</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:07:05
they're very complicated. They use something called attention. And I'm now going to try and give you an analogy for how words work. Um, this is fairly ambitious because I think people have completely the wrong model of how language models reality. So, I want to give you an alternative model. It's not perfect. It's an analogy. There's lots of things wrong with it, but it sort of gives you something to hang on to in thinking about how we use language to model reality because we need some way</p>
<p class="chinese-text">00:07:05
它们非常复杂。他们使用一种叫做注意力的东西。现在我将尝试为您提供一个关于词语如何运作的类比。嗯，这是相当雄心勃勃的，因为我认为人们对语言如何模拟现实的模型完全错误。所以，我想给你一个替代模型。它并不完美。这是一个类比。它有很多问题，但它在某种程度上给了你一些东西来思考我们如何使用语言来模拟现实，因为我们需要某种方式</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:07:34
of modeling things. That's what meaning is. Meaning is having a model. So think of words as like highdimensional Lego blocks. With Lego blocks, you can model any 3D shape moderately well. Don't worry about the surface, which may be sort of rectangular, but the volume you can model pretty well if it's big with 3D Lego blocks. Think of words as like Lego blocks, but instead of being 3D, they're like thousanddimensional. Now, that's a bit of a problem for most people cuz they're not sure how to think</p>
<p class="chinese-text">00:07:34
建模事物。这就是意义所在。意义就是有一个模型。因此，可以将单词视为高维乐高积木。使用乐高积木，您可以很好地对任何 3D 形状进行建模。不必担心表面，它可能是矩形的，但如果使用 3D 乐高积木很大，则可以很好地建模体积。可以将单词想象成乐高积木，但它们不是 3D 的，而是千维的。现在，这对大多数人来说都是一个问题，因为他们不知道如何思考</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:08:01
about a thousand dimensions. I'll tell you how everybody does it. You think of a three-dimensional thing like a Lego block and you say thousand to yourself very loudly. That's the best you can do. So there these thousand dimensional Lego blocks and so the shapes are very complicated because they're in thousand dimensions. And we can use combinations of those to model anything at all. Not just the distribution of matter in 3D but anything like theories of how the brain works. Now, instead of having just a few</p>
<p class="chinese-text">00:08:01
大约有一千个维度。我会告诉你每个人都是怎么做的。你想到像乐高积木这样的三维物体，然后你大声对自己说“千”。这是你能做的最好的事情了。这些一千维的乐高积木的形状非常复杂，因为它们是一千维的。我们可以使用这些组合来建模任何东西。不仅仅是物质在 3D 中的分布，还有诸如大脑如何工作的理论。现在，不再是只有几个</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:08:31
different kinds of Lego block, we've got thousands of different kinds of these special highdimensional Lego blocks, namely all the different words. And each one isn't a fixed shape. Each one has a range of shapes it can adopt. It's flexible. It can distort. It can't adopt any old shape. Once you know what the word is, you constrained with the shape. There may be several alternative shapes like for the word may, but for things that only have one central meaning, there's just a sort of a range of</p>
<p class="chinese-text">00:08:31
不同种类的乐高积木，我们有数千种不同种类的特殊高维乐高积木，即所有不同的单词。而且每一个都没有固定的形状。每个都有一系列可以采用的形状。它很灵活。它会扭曲。它不能采用任何旧的形状。一旦你知道了这个词是什么，你就受到了形状的限制。可能有几种替代形状，例如“may”这个词，但对于只有一个中心含义的事物，只有一系列的</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:08:59
possible shapes. And what they do is they deform to fit in with the other words in the context. So the context gives a particular shape to each word. I should say at this point in transformers it really happens with word fragments, but let's just suppose it's words. And instead of thinking of them fitting together by using little plastic cylinders that plug into holes like Lego blocks do, a very kind of rigid way of fitting together, think of the words as having lots of little hands on them. And</p>
<p class="chinese-text">00:08:59
可能的形状。它们所做的就是变形以适应上下文中的其他单词。因此，上下文赋予每个单词特定的形状。我应该说，在变形金刚中，这确实发生在单词片段上，但我们假设它是单词。不要认为它们是通过使用像乐高积木那样插入孔中的小塑料圆柱体来组装在一起的，这是一种非常严格的组装方式，而是将这些单词想象成有很多小手放在它们上面。和</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:09:30
these hands have funny shapes. And the way they fit together with other words is they do handshakes. That's called query key handshakes in a transformer. And actually as you change the precise vector that you're using for the meaning of a word, as the context changes that you actually change the shapes of the hands. So it's slightly more complicated than they have a fixed set of hand shapes. The hand shapes change as you change as you deform them. And what they want to do is they want to deform in</p>
<p class="chinese-text">00:09:30
这些手的形状很有趣。它们与其他词的配合方式是握手。这称为变压器中的查询密钥握手。实际上，当你改变用于表达单词含义的精确向量时，随着上下文的变化，你实际上会改变手的形状。所以它比他们有一套固定的手形要稍微复杂一些。当你变形时，手的形状也会改变。他们想要做的是他们想要变形</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:09:59
such a way that they change their hand shapes so that the words in the context can shake hands with other words. And that's what understanding is. Understanding is taking those words, finding how to deform them and how to deform their hands so they can shake hands with other words and then you've got a structure. It's a bit like a bunch of ammonia forming a structure but a lot more complicated and in a thousand dimensions. That's my image of what understanding is. Understanding is you</p>
<p class="chinese-text">00:09:59
他们改变手的形状，以便上下文中的单词可以与其他单词握手。这就是理解。理解就是接受这些单词，找到如何使它们变形以及如何使他们的手变形，以便他们可以与其他单词握手，然后你就得到了一个结构。它有点像一堆氨形成的结构，但要复杂得多，有一千个维度。这就是我对理解的理解。理解就是你</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:10:26
take these word symbols and the word symbols don't mean anything by themselves. They need an interpreter and you're the interpreter. your brain is and it deforms these thousand dimensional shapes roughly a thousand so that their hands will deform so they can all shake hands with other ones and so now you formed a structure and that's what it means to understand something to form that structure that structure is understanding. So the large language models, if you want to model all of human knowledge,</p>
<p class="chinese-text">00:10:26
拿这些文字符号来说，文字符号本身并没有任何意义。他们需要一名口译员，而您就是口译员。你的大脑使这一千个维度的形状变形了大约一千个，这样他们的手就会变形，这样他们就可以与其他人握手，所以现在你形成了一个结构，这就是理解某些东西以形成该结构所理解的结构的含义。所以大型语言模型，如果你想模拟所有人类知识，</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:10:57
they're complicated. They have many layers, very complicated interactions. And so it's very hard to analyze what they've actually learned and to see that they really are understanding what they're saying, particularly if you have the wrong model of understanding. So people influenced by symbolic AI and by um Chsky and those other linguists questioned whether they really were intelligent or whether they really understood what they were saying. And they used two main arguments. One was</p>
<p class="chinese-text">00:10:57
他们很复杂。它们有很多层次，相互作用非常复杂。因此，很难分析他们实际学到的内容并了解他们是否真正理解自己所说的内容，特别是如果你的理解模型错误的话。因此，受到符号人工智能、嗯 Chsky 和其他语言学家影响的人们质疑他们是否真的聪明，或者他们是否真正理解自己在说什么。他们使用了两个主要论点。一个是</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:11:22
they said it's just autocomplete. It's just using statistical correlations to paste together bits of text and predict the next word. And the text was all created by people so it's not creative at all. Well actually it beats most people on stand test of creativity. So that's not a very good argument. And then the second argument they used was well they hallucinate which shows they don't really understand anything. So let's take the autocomplete objection. In the old days when you did</p>
<p class="chinese-text">00:11:22
他们说这只是自动完成。它只是使用统计相关性将文本片段粘贴在一起并预测下一个单词。而且文字都是人写的，没有什么创意。事实上，它在创造力的经受考验中击败了大多数人。所以这不是一个很好的论点。然后他们使用的第二个论点是他们产生了幻觉，这表明他们并不真正理解任何事情。那么让我们以自动完成反对为例。过去当你这么做的时候</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:11:49
autocomplete, you keep tables of how often particular combinations of words occurred. So in a simple case, you might store tables of how often triples of words occurred. And then if you saw fish and you'd realize that fish and chips occurs a lot of times, so that's a likely next word. I actually gave this talk in the House of Lords and realized that there fish and hunt is probably more likely than fish and chips. But um there are obviously alternatives, but that's not at all how LLM's predict the</p>
<p class="chinese-text">00:11:49
自动完成，您可以保存特定单词组合出现频率的表格。因此，在简单的情况下，您可以存储单词三元组出现频率的表格。然后，如果你看到鱼，你就会意识到鱼和薯条出现了很多次，所以这可能是下一个词。事实上，我在上议院做了这次演讲，并意识到钓鱼和狩猎可能比炸鱼和薯条更有可能。但嗯，显然还有其他选择，但这根本不是法学硕士预测的方式</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:12:16
next word. that's disappeared. They don't store any text. They don't store any tables of combinations of words. They model all the text they've seen by inventing feature vectors for words that can deform with contextual influences. And these complicated interactions between these word fragments by these handshakes. And that's what their knowledge is. Their knowledge is in those interactions. It's a bunch of weights in the neural network. So that's what knowledge is in these large language</p>
<p class="chinese-text">00:12:16
下一个词。那已经消失了。他们不存储任何文本。它们不存储任何单词组合表。他们通过发明可因上下文影响而变形的单词特征向量，对所见过的所有文本进行建模。这些握手使这些单词片段之间产生了复杂的相互作用。这就是他们的知识。他们的知识就在这些互动中。它是神经网络中的一堆权重。这就是这些大语言中的知识</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:12:48
models and it's what knowledge is in us too. The original tiny language model wasn't invented to be good at modeling natural language. It was invented to explain how we can understand the senses of words. How can I take a sentence like she scrummed him with the frying pan? I've never heard the word scrum before but in one sentence I already know a lot about what it means because of the hole created by the context tells you what it ought to mean. So my claim is that we model reality by using these word</p>
<p class="chinese-text">00:12:48
模型，这也是我们体内的知识。最初的微型语言模型并不是为了擅长对自然语言进行建模而发明的。它的发明是为了解释我们如何理解词义。我怎么能接受她用煎锅炒他这样的一句话？我以前从未听说过 scrum 这个词，但在一句话中我已经知道了很多它的含义，因为上下文造成的漏洞告诉你它应该是什么意思。所以我的主张是我们通过使用这些词来模拟现实</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:13:20
fragments in much the same way as machines do. It's obviously not exactly the same. Another argument is well hallucinations show they don't really understand anything. First of all, they should be called confabulations. They've been studied by psychologists for a long time and they're very characteristic of people. We store knowledge in weights, not in stored strings. We think we store files in memory and then retrieve the files from memory. But our memory doesn't work like that at all. We make</p>
<p class="chinese-text">00:13:20
碎片的方式与机器非常相似。显然不完全一样。另一个论点是幻觉表明他们并不真正理解任何事情。首先，它们应该被称为虚构。心理学家对它们进行了很长时间的研究，它们非常具有人的特征。我们将知识存储在权重中，而不是存储在字符串中。我们认为我们将文件存储在内存中，然后从内存中检索文件。但我们的记忆根本不是这样运作的。我们做</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:13:45
up a memory when we need it. We construct it. It's a very constructive business. It's not stored anywhere. It's created when we need it. And so it'll be influenced by things we learned since the events happened. And we'll be very confident by the details that we get wrong. There's a very nice example of that which is John Dean's memory when he testified at the Watergate TR. He was testifying about what happened in the Oval Office about meetings in the Oval Office and he had</p>
<p class="chinese-text">00:13:45
当我们需要的时候，就可以建立一个记忆。我们建造它。这是一项非常有建设性的业务。它没有存储在任何地方。它是在我们需要时创建的。因此，它将受到事件发生以来我们学到的东西的影响。我们会对我们出错的细节非常有信心。约翰·迪恩 (John Dean) 在水门事件 TR 作证时的记忆就是一个很好的例子。他正在就椭圆形办公室内发生的有关椭圆形办公室会议的事情作证，他有</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:14:09
no idea that there were tapes but he was trying to tell the truth and you can see that he's wrong about huge numbers of details meeting. He says there were meetings between these people. Those meetings never happened. He says this person said one thing actually was somebody else said that. But you can also see that the gist of what he said was exactly right. There was a cover up going on and those were the kinds of things people said. So what he was doing was he was creating these meetings, creating them in his</p>
<p class="chinese-text">00:14:09
不知道有录音带，但他试图说出真相，你可以看到他对大量细节会议的看法是错误的。他说这些人之间有过会面。那些会议从未发生过。他说这个人说的一件事实际上是别人说的。但你也可以看出，他说的大意是完全正确的。有人在掩盖真相，人们也这么说。所以他所做的就是创建这些会议，在他自己的环境中创建它们。</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:14:34
mind and what he was creating was what seemed plausible to him. That's exactly what the chatbots do, but it's also exactly what people do. Now currently chatbots are worse than most non-presidents at knowing whether they're just making it up. But that's going to change. So finally, if you ask how do we share knowledge with each other? Well, we've got these words that have names. And so I make this structure out of these complicated thousand dimensional le Lego block shaking hands.</p>
<p class="chinese-text">00:14:34
他的想法和他正在创造的东西对他来说似乎是合理的。这正是聊天机器人所做的事情，但也正是人们所做的事情。目前，聊天机器人比大多数非总统更不知道自己是否在编造故事。但这种情况将会改变。最后，如果你问我们如何相互分享知识？好吧，我们已经有了这些有名字的单词。所以我用这些复杂的千维乐高积木握手来制作这个结构。</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:15:03
And I can't tell you all that structure, but I can tell you the names of the words. And now you can create the same structure using the names of the words. I can also put into these complicated thousand dimensional things little clues about what should shake hands with what. That's called syntax. The symbolic AI theory is we share knowledge by copying a proposition from my head to your head or from my head to the computer and this proposition is written in this funny logical language. The neural net theory</p>
<p class="chinese-text">00:15:03
我无法告诉你所有的结构，但我可以告诉你单词的名称。现在您可以使用单词的名称创建相同的结构。我还可以在这些复杂的千维事物中加入一些关于什么应该与什么握手的线索。这就是所谓的语法。符号人工智能理论是我们通过将一个命题从我的大脑复制到你的大脑或从我的大脑复制到计算机来共享知识，并且这个命题是用这种有趣的逻辑语言编写的。神经网络理论</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:15:35
is that you have a teacher and a student and the teacher produces a produce some action and the student tries to mimic it. So for language the teacher produces a string of words. The student tries to predict the next word and takes the errors in predicting the next word and back propagates them to learn how you should convert symbols into feature vectors these thousand dimensional Lego blocks and how these things should interact. That's called distillation. And the problem is it's very inefficient. That's also how we get</p>
<p class="chinese-text">00:15:35
就是你有一个老师和一个学生，老师做出一些动作，学生尝试模仿它。因此，对于语言，老师会产生一串单词。学生尝试预测下一个单词，并获取预测下一个单词的错误，并将它们反向传播，以学习如何将符号转换为这些千维乐高积木的特征向量，以及这些东西应该如何相互作用。这就是所谓的蒸馏。问题是效率非常低。这也是我们得到的方式</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:16:07
knowledge from people into computers. So that's how these large language models learn by trying to predict the next word a person said. But it's not efficient. If you take a typical sentence, string of symbols, it's only got about 100 bits. It's a few hundred or maybe less than 100, but it's that order. And that means the most that a student can get is 100 bits of information because that's all there is in the sentence. That's not a very big learning signal. Now compare</p>
<p class="chinese-text">00:16:07
知识从人到计算机。这就是这些大型语言模型通过尝试预测一个人所说的下一个单词来学习的方式。但这效率不高。如果你看一个典型的句子、符号串，它只有大约 100 位。虽然有几百个，也可能不到一百个，但就是这个顺序。这意味着学生最多可以获得 100 位信息，因为这就是句子中的全部信息。这不是一个很大的学习信号。现在比较一下</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:16:34
that with what happens when you have multiple copies of the same agent and it's a digital agent. So these digital agents, you can have multiple copies. The multiple copies have exactly the same weights. They work exactly the same way because they're digital. And so one copy looks at one bit of the internet, another copy looks at another bit of the internet. They both figure out how they'd like to change their weights. And then they share how they'd like to change their weights. So now both copies</p>
<p class="chinese-text">00:16:34
当您拥有同一代理的多个副本并且它是数字代理时会发生什么。所以这些数字代理，你可以拥有多个副本。多个副本的重量完全相同。它们的工作方式完全相同，因为它们是数字化的。因此，一份副本查看互联网的一部分，另一份副本查看互联网的另一部分。他们都想出了如何改变自己的体重。然后他们分享了他们想要如何改变体重。所以现在两个副本</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:16:58
know what each copy experienced. And if you ask how much are they sharing when they share their weights or the gradients for their weights, they're sharing trillions of bits if they've got trillions of weights. So you're talking about the difference between being able to share trillions of bits and being able to share hundreds of bits. It's really no competition. It only works if the agents are digital and use their weights in exactly the same way and have exactly the same weights, but it's hugely more efficient.</p>
<p class="chinese-text">00:16:58
知道每个副本经历了什么。如果你问他们在共享权重或权重梯度时共享了多少，那么如果他们有数万亿的权重，他们就会共享数万亿比特。所以你谈论的是能够共享数万亿比特和能够共享数百比特之间的区别。这确实没有竞争。只有当智能体是数字化的并且以完全相同的方式使用它们的权重并且具有完全相同的权重时，它才有效，但它的效率要高得多。</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:17:25
And that's why GPT4 can know thousands of times more than any one person. It's a not very good expert at everything. So the conclusions are that digital agents understand language in much the same way as people do. It's not a completely different kind of system. We we are like them and they are like us. They're much more like us than they are like standard computer code. Digital computation requires a lot more energy because it's digital. So you have to drive transistors very hard. You can't use the</p>
<p class="chinese-text">00:17:25
这就是为什么 GPT4 的知识比任何一个人都多数千倍。它不是一个在所有事情上都非常优秀的专家。因此，结论是数字代理理解语言的方式与人类大致相同。这并不是一种完全不同的系统。我们和他们一样，他们也和我们一样。与标准计算机代码相比，它们更像我们。数字计算需要更多的能量，因为它是数字的。所以你必须非常努力地驱动晶体管。你不能使用</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
<div class="paragraph-block">
<p class="english-text">00:17:52
funny quirky properties of analog hardware. But because they're digital, they have this really efficient means of sharing. They can share weights or gradients. Biological computation is much lower power because it can use all the quirky properties of neurons. But it's no good at sharing knowledge. So the overall conclusion is that if energy is cheap or at least abundant, digital computation is just better because it can share knowledge efficiently. And that's a very scary conclusion.</p>
<p class="chinese-text">00:17:52
模拟硬件的有趣古怪的特性。但由于它们是数字化的，因此它们拥有这种非常有效的共享方式。他们可以共享权重或梯度。生物计算的功率要低得多，因为它可以利用神经元的所有古怪特性。但它不利于分享知识。因此，总体结论是，如果能源便宜或至少丰富，数字计算会更好，因为它可以有效地共享知识。这是一个非常可怕的结论。</p>
</div>
<div class="paragraph-block">

<p class="chinese-text">[翻译占位 - 翻译占位符]</p>
</div>
</div>

    <!-- Translation Tooltip HTML -->
    <div class="translation-tooltip" id="translationTooltip" style="display: none; position: fixed; max-width: 400px; background-color: rgba(255, 255, 255, 0.98); border: 2px solid #5a3e2b; border-radius: 8px; padding: 15px; box-shadow: 0 4px 20px rgba(0,0,0,0.2); z-index: 1000; font-family: 'Microsoft YaHei', sans-serif;">
        <div class="tooltip-translation" style="color: #5a3e2b; font-size: 1rem; font-weight: 500; line-height: 1.6;">翻译中...</div>
    </div>
    <!-- Translation Script -->
    <script>
        // Article Translation Features
        // Features: Click-to-translate near cursor
        
        // Global variables
        let selectedParagraph = null;
        
        // Translation API (using free MyMemory API)
        const TRANSLATION_API = 'https://api.mymemory.translated.net/get';
        
        // DOM elements
        let translationTooltip;
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', function() {
            // Get DOM elements
            translationTooltip = document.getElementById('translationTooltip');
            
            // Add click listener to close tooltip when clicking outside
            document.addEventListener('click', function(e) {
                // Check if click is outside tooltip and not on a selectable paragraph
                if (translationTooltip && 
                    !translationTooltip.contains(e.target) && 
                    !e.target.classList.contains('selectable')) {
                    hideTranslation();
                }
            });
            
            // Add selectable class to all English text paragraphs in articles
            const englishParagraphs = document.querySelectorAll('.english-text');
            englishParagraphs.forEach(paragraph => {
                // Only make English text selectable
                if (paragraph.textContent.trim()) {
                    paragraph.classList.add('selectable');
                    
                    // Add click listener for translation
                    paragraph.addEventListener('click', function(e) {
                        e.stopPropagation(); // Prevent document click from firing
                        handleParagraphClick(this, e);
                    });
                }
            });
        });
        
        // Handle paragraph click for translation
        function handleParagraphClick(element, event) {
            // Remove previous selection
            if (selectedParagraph) {
                selectedParagraph.classList.remove('selected');
            }
            
            // Mark as selected
            element.classList.add('selected');
            selectedParagraph = element;
            
            // Get the text to translate
            const textToTranslate = element.textContent;
            
            // Position tooltip near the click
            positionTooltip(event);
            
            // Show tooltip with loading state
            showTranslation(textToTranslate);
            
            // Fetch translation
            translateText(textToTranslate);
        }
        
        // Position tooltip near cursor but ensure it stays on screen
        function positionTooltip(event) {
            const tooltip = translationTooltip;
            const offset = 15; // Offset from cursor
            
            // Get viewport dimensions
            const viewportWidth = window.innerWidth;
            const viewportHeight = window.innerHeight;
            
            // Initial position near cursor
            let left = event.pageX + offset;
            let top = event.pageY + offset;
            
            // Show tooltip temporarily to get its dimensions
            tooltip.style.display = 'block';
            tooltip.style.left = left + 'px';
            tooltip.style.top = top + 'px';
            
            // Get tooltip dimensions
            const tooltipRect = tooltip.getBoundingClientRect();
            const tooltipWidth = tooltipRect.width;
            const tooltipHeight = tooltipRect.height;
            
            // Adjust if tooltip goes off right edge
            if (event.clientX + tooltipWidth + offset > viewportWidth) {
                left = event.pageX - tooltipWidth - offset;
            }
            
            // Adjust if tooltip goes off bottom edge
            if (event.clientY + tooltipHeight + offset > viewportHeight) {
                top = event.pageY - tooltipHeight - offset;
            }
            
            // Ensure tooltip doesn't go off left or top edges
            if (left < 10) left = 10;
            if (top < 80) top = 80; // Account for top nav
            
            // Set final position
            tooltip.style.left = left + 'px';
            tooltip.style.top = top + 'px';
        }
        
        // Show translation tooltip
        function showTranslation(originalText) {
            const translationDiv = translationTooltip.querySelector('.tooltip-translation');
            
            // Show loading state
            translationDiv.textContent = '翻译中...';
            translationDiv.style.color = '#999';
            
            // Show tooltip
            translationTooltip.style.display = 'block';
        }
        
        // Hide translation tooltip
        function hideTranslation() {
            translationTooltip.style.display = 'none';
            if (selectedParagraph) {
                selectedParagraph.classList.remove('selected');
                selectedParagraph = null;
            }
        }
        
        // Translate text using free API
        async function translateText(text) {
            const translationDiv = translationTooltip.querySelector('.tooltip-translation');
            
            // Limit text length for API (MyMemory has a 500 character limit)
            const textToTranslate = text.length > 500 ? text.substring(0, 500) : text;
            
            // If text is too long, split it into chunks
            const maxChunkLength = 500; // MyMemory API limit
            
            if (text.length <= maxChunkLength) {
                // Short text - translate directly
                try {
                    const url = `${TRANSLATION_API}?q=${encodeURIComponent(text)}&langpair=en|zh-CN`;
                    const response = await fetch(url);
                    const data = await response.json();
                    
                    if (data.responseStatus === 200 && data.responseData) {
                        const translation = data.responseData.translatedText;
                        translationDiv.textContent = translation;
                        translationDiv.style.color = '#5a3e2b';
                    } else {
                        translationDiv.textContent = '翻译失败,请稍后重试';
                        translationDiv.style.color = '#d9534f';
                    }
                } catch (error) {
                    console.error('Translation error:', error);
                    translationDiv.textContent = '翻译服务暂时不可用';
                    translationDiv.style.color = '#d9534f';
                }
            } else {
                // Long text - split into chunks
                try {
                    // Split text into chunks of maxChunkLength, trying to break at sentence boundaries
                    const chunks = [];
                    let currentChunk = '';
                    
                    // First, try to split by sentence endings
                    const sentences = text.match(/[^.!?。！？]+[.!?。！？]*/g) || [text];
                    
                    for (const sentence of sentences) {
                        if ((currentChunk + sentence).length <= maxChunkLength) {
                            currentChunk += sentence;
                        } else {
                            if (currentChunk) {
                                chunks.push(currentChunk);
                            }
                            // If single sentence is too long, force split by maxChunkLength
                            if (sentence.length > maxChunkLength) {
                                for (let i = 0; i < sentence.length; i += maxChunkLength) {
                                    chunks.push(sentence.substring(i, i + maxChunkLength));
                                }
                                currentChunk = '';
                            } else {
                                currentChunk = sentence;
                            }
                        }
                    }
                    
                    if (currentChunk) {
                        chunks.push(currentChunk);
                    }
                    
                    // Translate each chunk
                    let fullTranslation = '';
                    for (let i = 0; i < chunks.length; i++) {
                        const chunk = chunks[i];
                        const url = `${TRANSLATION_API}?q=${encodeURIComponent(chunk)}&langpair=en|zh-CN`;
                        const response = await fetch(url);
                        const data = await response.json();
                        
                        if (data.responseStatus === 200 && data.responseData) {
                            fullTranslation += data.responseData.translatedText;
                            // Update display with progress
                            translationDiv.textContent = fullTranslation + ' [翻译中...]';
                        } else {
                            fullTranslation += '[翻译失败]';
                        }
                        
                        // Add small delay to avoid rate limiting
                        if (i < chunks.length - 1) {
                            await new Promise(resolve => setTimeout(resolve, 200));
                        }
                    }
                    
                    translationDiv.textContent = fullTranslation;
                    translationDiv.style.color = '#5a3e2b';
                } catch (error) {
                    console.error('Translation error:', error);
                    translationDiv.textContent = '翻译服务暂时不可用';
                    translationDiv.style.color = '#d9534f';
                }
            }
        }
        
        // Add CSS for selected state
        const style = document.createElement('style');
        style.textContent = `
            .selectable {
                cursor: pointer;
                transition: background-color 0.2s ease;
                padding: 2px 4px;
                border-radius: 3px;
            }
            
            .selectable:hover {
                background-color: rgba(212, 167, 106, 0.2);
            }
            
            .selectable.selected {
                background-color: rgba(212, 167, 106, 0.4);
            }
            
            .translation-tooltip {
                animation: fadeIn 0.2s ease;
            }
            
            @keyframes fadeIn {
                from {
                    opacity: 0;
                    transform: translateY(-5px);
                }
                to {
                    opacity: 1;
                    transform: translateY(0);
                }
            }
        `;
        document.head.appendChild(style);
    </script>
    </body>
</html>